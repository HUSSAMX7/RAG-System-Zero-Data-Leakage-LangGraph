{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "023981db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! I can give you a more detailed explanation of the topic or provide more information about specific aspects of it. Just let me know what you would like to learn more about.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 12, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bw3cE0ZeTM44zzlSxeq4G8fqnoKTH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bb526165-91f0-40e5-923a-cbedddf22ecf-0', usage_metadata={'input_tokens': 12, 'output_tokens': 36, 'total_tokens': 48, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=\"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\")\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "        llm=llm,\n",
    "        memory_key=\"chat_history\",\n",
    "        input_key=\"question\",\n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "        {\"input\": \"my name is hussamssss\", \"output\": \"your name is husam.\"},\n",
    "        {\"input\": \"Explain more.\", \"output\": \" retrieves documents and  generates answers.\"},\n",
    "        {\"input\": \"my son his name is fahad\", \"output\": \"your name is hussam.\"}\n",
    "    ]\n",
    "\n",
    "for msg in messages:\n",
    "        memory.save_context(\n",
    "            {\"question\": msg[\"input\"]},\n",
    "            {\"output\": msg[\"output\"]}\n",
    "        )\n",
    "\n",
    "\n",
    "llm.invoke(\"talk more about it \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1620c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The son's name is Fahad.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    This is the conversation so far:\n",
    "    {chat_history}\n",
    "\n",
    "    Now answer this new question:\n",
    "    {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": \"what is son name?\"})\n",
    "print(response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05695612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"The human introduces themselves as Hussam, but the AI corrects the spelling to Husam, and later when the human mentions their son Fahad, the AI reiterates that the human's name is Hussam. The AI indicates its ability to retrieve documents and generate answers for inquiries.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})[\"chat_history\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-add",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
